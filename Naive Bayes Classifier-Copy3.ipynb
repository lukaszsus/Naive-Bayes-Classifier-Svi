{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.optim as optim\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.distributions import constraints\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(1)\n",
    "pyro.enable_validation(True)\n",
    "pyro.clear_param_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wilt_atrr = ['GLCM_pan', 'Mean_Green', 'Mean_Red', 'Mean_NIR', 'SD_pan']\n",
    "\n",
    "# loading datasets\n",
    "df = pd.read_csv('wine.data', header=None)\n",
    "# X = torch.from_numpy(wine.iloc[:,1:-1].values)\n",
    "# y = torch.from_numpy(wine.iloc[:,0].astype(int).values)\n",
    "X = df.iloc[:,1:-1]\n",
    "y = df.iloc[:,0].astype(int)\n",
    "y = y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "softplus = torch.nn.Softplus() # takie ReLU tylko ciągłe\n",
    "\n",
    "def model(X):\n",
    "    # rejestrujemy zmienną do przestrzeni optymalizacji (store pyro)\n",
    "    mu_param = pyro.param(\"mu\", torch.zeros_like(naive_bayes.current_class_probs))\n",
    "    # ograniczamy wartości do nieujemnych\n",
    "    sigma_param = pyro.param(\"sigma\", torch.ones_like(naive_bayes.current_class_probs), constraint=constraints.positive)\n",
    "    params = pyro.distributions.Normal(loc=mu_param, scale=sigma_param).to_event(1)\n",
    "    with pyro.plate(\"map\", len(X)):\n",
    "        pyro.sample(\"probs\", params, obs=X)\n",
    "\n",
    "def guide(X):\n",
    "    # rejestrujemy zmienną do przestrzeni optymalizacji (store pyro)\n",
    "    mu_param = pyro.param(\"mu\", torch.zeros_like(naive_bayes.current_class_probs))\n",
    "    # ograniczamy wartości do nieujemnych\n",
    "    sigma_param = pyro.param(\"sigma\", torch.ones_like(naive_bayes.current_class_probs), constraint=constraints.positive)\n",
    "    probs_prior = pyro.distributions.Normal(loc=mu_param, scale=sigma_param).to_event(1)\n",
    "    return pyro.sample(\"probs\", probs_prior, infer={'is_auxiliary': True})\n",
    "\n",
    "def train(X):\n",
    "    pyro.clear_param_store()\n",
    "    num_iterations=5000\n",
    "    optim = pyro.optim.Adam({\"lr\": 0.01})\n",
    "    svi = pyro.infer.SVI(model, guide, optim, loss=pyro.infer.Trace_ELBO(), num_samples=len(X))\n",
    "    losses = list()\n",
    "    t=tqdm(range(num_iterations))\n",
    "    for j in t:\n",
    "        loss = svi.step(X)\n",
    "        losses.append(loss)\n",
    "        t.set_postfix(loss=loss)\n",
    "    return (svi, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        self.available_y = np.unique(y)\n",
    "        self.num_features = X.shape[1]\n",
    "        self._count_y_prob()\n",
    "        self.params_for_probs = list()\n",
    "        \n",
    "        for target in self.available_y:\n",
    "            self.X_current_class = torch.from_numpy(X[y==target])\n",
    "            self.current_class_probs = torch.from_numpy(np.random.randn(self.num_features))\n",
    "            train(self.X_current_class)\n",
    "            mu = pyro.param(\"mu\")\n",
    "            sigma = pyro.param(\"sigma\")\n",
    "            self.params_for_probs.append(torch.stack([mu, sigma], dim=0))\n",
    "            \n",
    "        for i in range(len(self.params_for_probs)):\n",
    "            self.params_for_probs[i] = self.params_for_probs[i].detach().numpy()\n",
    "            \n",
    "    def _count_y_prob(self):\n",
    "        total_quantity = len(self.y)\n",
    "        self.p_y = [np.count_nonzero(self.y == i) / total_quantity for i in self.available_y]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predicted = list()\n",
    "        for i in range(len(X)):\n",
    "            predicted.append(self._predict_one_example(i, X[i, :]))\n",
    "        return np.asarray(predicted)\n",
    "\n",
    "    def _predict_one_example(self, i: int, x: np.ndarray):\n",
    "        certainity_for_ys = list()\n",
    "        for y in self.available_y:  # for every class\n",
    "            certainity_for_ys.append(self.p_y[y])\n",
    "            for i in range(len(x)):  # for every feature\n",
    "                certainity_for_ys[-1] *= self._p_xi_on_condition_y(i, y, x[i])\n",
    "        return self.available_y[certainity_for_ys.index(max(certainity_for_ys))]\n",
    "    \n",
    "    def _p_xi_on_condition_y(self, feature_index, y_index, x_i):\n",
    "#         print(y_index)\n",
    "#         print(feature_index)\n",
    "#         print(self.params_for_probs)\n",
    "        multiplier = 1 / np.sqrt(2 * np.pi * self.params_for_probs[y_index][0, feature_index])\n",
    "        exp = - (x_i - self.params_for_probs[y_index][1, feature_index]) ** 2 / (2 * self.params_for_probs[y_index][0, feature_index])\n",
    "        return multiplier * np.power(np.e, exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes = NaiveBayesClassifier()\n",
    "# naive_bayes.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossval_research(data, target):\n",
    "    splitter = StratifiedKFold(n_splits=7, shuffle=True)\n",
    "    split_set_generator = splitter.split(data, target)\n",
    "\n",
    "    # trainning and testing\n",
    "    y_pred = list()\n",
    "    y_true = list()\n",
    "\n",
    "    train_indices, test_indices = next(split_set_generator)\n",
    "#     print(type(train_indices))\n",
    "#     print(type(data))\n",
    "#     print(data)\n",
    "    X_train = data[train_indices]\n",
    "    Y_train = target[train_indices]\n",
    "    naive_bayes.fit(X_train, Y_train)\n",
    "    y_pred.extend(naive_bayes.predict(data[test_indices]))\n",
    "    y_true.extend(target[test_indices])\n",
    "\n",
    "    confusion = metrics.confusion_matrix(y_true, y_pred)\n",
    "    accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "    precision = metrics.precision_score(y_true, y_pred, average=None)\n",
    "    recall = metrics.recall_score(y_true, y_pred, average=None)\n",
    "    f1_score = metrics.f1_score(y_true, y_pred, average=None)\n",
    "\n",
    "    return {\"confusion\": confusion, \"accuracy\": accuracy, \"precision\": precision,\n",
    "            \"recall\": recall, \"f1_score\": f1_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f9373d4a82461da420f405789b2853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049034e37c134d1eaec68aa780a85470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af5a507f87f4473b45b1ea089c327b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "class_metrics = crossval_research(X.values, y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu\n",
      "sigma\n",
      "tensor([13.0939,  3.3176,  2.4561,  5.9368,  3.9697,  1.7212,  0.8012,  0.4476,\n",
      "         1.1849,  7.4583,  0.6851,  1.6778], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "tensor([ 1.3414,  1.1298,  0.1809, 16.7009, 44.4260,  0.3561,  0.2915,  0.1227,\n",
      "         0.4022,  2.3089,  0.1171,  0.2617], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "param_store = pyro.get_param_store()\n",
    "for key in param_store.keys():\n",
    "    print(key)\n",
    "    \n",
    "print(pyro.param(\"mu\"))\n",
    "print(pyro.param(\"sigma\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'confusion': array([[9, 0, 0],\n",
      "       [9, 0, 2],\n",
      "       [0, 0, 7]]), 'accuracy': 0.5925925925925926, 'precision': array([0.5       , 0.        , 0.77777778]), 'recall': array([1., 0., 1.]), 'f1_score': array([0.66666667, 0.        , 0.875     ])}\n"
     ]
    }
   ],
   "source": [
    "print(class_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33112582781456956, 0.3973509933774834, 0.271523178807947]\n"
     ]
    }
   ],
   "source": [
    "print(naive_bayes.p_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
